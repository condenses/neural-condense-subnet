<div align="center">
<picture>
    <source srcset="./assets/images/condense-main.png">
    <img src="./assets/images/condense-main.png" alt="Neural Condense Subnet" style="width:800px;">

</picture>
</div>

<div align="center">

# ⚡ 

</div>


## 🌟 Key Features:

### ⚡ Subnet as an Accelerate Adapter for LLM Inference
- ✅ **Seamless Integration:** Effortlessly integrates with LLM inference engines, such as `transformers`.
- ✅ **Flexible Support:** Flexible to support any LLM model with any size.
- ✅ **Incentive Mechanism:** Designed with a strong, evolving incentive structure, encouraging miners to innovate.
- ✅ **Fully Decentralized Validator**: No Centralized API.
- ✅ **Fast & High Workload:** Miners are categorized by tier. 
- ✅ **Tiered Nodes:** Nodes are categorized by tier.

### ⚙️ Node Tiers

| **Tier**       | **Purpose**                           | **Context Size**         | **Speed**     |
|----------------|---------------------------------------|---------------------------|---------------|
| `research`     | Warmup tier for new LLM model releases | Flexible                  | Unrestricted  |
| `inference_0`  | Optimized for **long context** in popular LLMs | Up to 1536 tokens       | Fast         |
| `inference_1`  | Optimized for **very long context** in popular LLMs | Up to 4096 tokens       | Fast         |

--- 


### 🔒 Subnet as a Data Encryption Layer for Bittensor
- ✅ **Neural Encrypted Conversations:** The subnet offers an additional benefit regarding privacy. If users or companies utilize a subnet to transform their context into condensed tokens before sending them to other LLM services, this approach can help prevent context leaks. The transformation increases the computational complexity, making it more difficult for unauthorized entities to extract the original context.


## 📚 Documentation
- Setup for miners: [Miner Setup](./docs/miner.md)
- Setup for validators: [Validator Setup](./docs/validator.md)
