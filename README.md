<div align="center">
<picture>
    <source srcset="./assets/images/condense-main.png">
    <img src="./assets/images/condense-main.png" alt="Neural Condense Subnet" style="width:800px;">

</picture>
</div>

<div align="center">

# ⚡ 

</div>


## 🌟 Key Features:

### ⚡ Subnet as an Accelerate Adapter for LLM Inference
- ✅ **Seamless Integration:** Effortlessly integrates with LLM inference engines, such as `transformers`.
- ✅ **Flexible Support:** Flexible to support any LLM model with any size.
- ✅ **Incentive Mechanism:** Designed with a strong, evolving incentive structure, encouraging miners to innovate.
- ✅ **Fully Decentralized Validator**: No Centralized API.
- ✅ **Fast & High Workload:** Miners are categorized by tier. 
- ✅ **Tiered Nodes:** Nodes are categorized by tier.

### ⚙️ Node Tiers

| **Tier**       | **Purpose**                           | **Context Size**         | **Speed**     |
|----------------|---------------------------------------|---------------------------|---------------|
| `research`     | Warmup tier for new LLM model releases | Flexible                  | Unrestricted  |
| `inference_0`  | Optimized for **long context** in popular LLMs | Up to 1536 tokens       | Fast         |
| `inference_1`  | Optimized for **very long context** in popular LLMs | Up to 4096 tokens       | Fast         |

--- 


### 🔒 Subnet as a Data Encryption Layer for Bittensor
- ✅ **Neural Encrypted Conversations:** Encrypts conversations into limited tokens


## 📚 Documentation
- Setup for miners: [Miner Setup](./docs/miner.md)
- Setup for validators: [Validator Setup](./docs/validator.md)
